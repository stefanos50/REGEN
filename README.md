

# REGEN: Real-Time Photorealism Enhancement in Games via a Dual-Stage Generative Network Framework

<div style="display: flex; justify-content: center; gap: 10px;">
  <a href="https://arxiv.org/abs/2508.17061" target="_blank">
    <img alt="Static Badge" src="https://img.shields.io/badge/PAPER-blue?style=for-the-badge&logo=arxiv&logoSize=auto">
  </a>
  <a href="https://www.youtube.com/watch?v=tEgk4ycpmpQ" target="_blank">
    <img alt="Static Badge" src="https://img.shields.io/badge/DEMO-red?style=for-the-badge&logo=YouTube&logoSize=auto">
  </a>
  <a href="https://drive.google.com/drive/folders/19Q8E9wy3MR-vUfOfVwytIzv4QNpndYo0" target="_blank">
<img alt="Static Badge" src="https://img.shields.io/badge/MODELS-orange?style=for-the-badge&logo=googledrive&logoSize=auto">
  </a>
    <a href="https://github.com/stefanos50/CARLA2Real" target="_blank">
<img alt="Static Badge" src="https://img.shields.io/badge/CARLA2Real_Project-black?style=for-the-badge&logo=github&logoSize=auto">
  </a>
</div>

## Demonstration

The following demo illustrates a side-by-side comparison of the framework performing `GTAV ‚Üí Cityscapes` (left) and `GTAV ‚Üí Mapillary Vistas` (right) at `1280x720 (maximum game settings)`. The footages were recorded with OBS Studio while the game was also rendered on the same GPU. It is running on a system with an `RTX 4090`, an `Intel i7 14700F CPU`, and `64GB of DDR4` system memory without any optimization (e.g., TensorRT). The full video is included in the `demos` directory.

<p align="center">
  <img src="./demos/gta2cs.gif" width="45%" />
  <img src="./demos/gta2vistas.gif" width="45%" />
</p>

The following demos illustrate the framework performing `GTAV ‚Üí Cityscapes` at `1280x720 (maximum game settings)` and `CARLA ‚Üí KITTI` at `960x540` with a 20 fps cap of the simulator in synchronous mode. Both are running on a system with an `RTX 4070 Super 12GB`, an `Intel i7 13700KF CPU`, and `32GB of DDR4` system memory without any optimization (e.g., TensorRT).

<p align="center">
  <img src="./demos/demo_gta.gif" width="45%" />
  <img src="./demos/demo_carla.gif" width="45%" />
</p>

## Abstract

Photorealism is an important aspect of modern video games since it can shape the player experience and simultaneously impact the immersion, narrative engagement, and visual fidelity. Although recent hardware technological breakthroughs, along with state-of-the-art rendering technologies, have significantly improved the visual realism of video games, achieving true photorealism in dynamic environments at real-time frame rates still remains a major challenge due to the tradeoff between visual quality and performance. In this short paper, we present a novel approach for enhancing the photorealism of rendered game frames using generative adversarial networks. To this end, we propose Real-time photorealism Enhancement in Games via a dual-stage gEnerative Network framework (REGEN), which employs a robust unpaired image-to-image translation model to produce semantically consistent photorealistic frames that transform the problem into a simpler paired image-to-image translation task. This enables training with a lightweight method that can achieve real-time inference time without compromising visual quality. We demonstrate the effectiveness of our framework on Grand Theft Auto V, showing that the approach achieves visual results comparable to the ones produced by the robust unpaired Im2Im method while improving inference speed by 32.14 times. Our findings also indicate that the results outperform the photorealism-enhanced frames produced by directly training a lightweight unpaired Im2Im translation method to translate the video game frames towards the visual characteristics of real-world images.

### BibTeX Citation

If you used the REGEN framwork or any of the pretrained models from this repository in a scientific publication, we would appreciate using the following citation:

```
@misc{pasios2025regenrealtimephotorealismenhancement,
      title={REGEN: Real-Time Photorealism Enhancement in Games via a Dual-Stage Generative Network Framework}, 
      author={Stefanos Pasios and Nikos Nikolaidis},
      year={2025},
      eprint={2508.17061},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.17061}, 
}
```

> üìù **Note**: This repository uses code from the [Pix2PixHD repository](https://github.com/NVIDIA/pix2pixHD).

## Requirements

```
conda create -n REGEN python=3.9
conda activate REGEN
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu128
pip install carla==0.9.15
pip install opencv-python
pip install dominate
pip install scipy
pip install mss
pip install pywin32
```

## Training

To train the model, it is required to have access to a synthetic dataset generated by a game or simulator and the corresponding images that were photorealism enhanced by a robust unpaired image-to-image translation method such as [Enhancing Photorealism Enhancement (EPE)](https://github.com/isl-org/PhotorealismEnhancement). 

### CARLA Simulator

To train a model that enhances the photorealism of the CARLA simulator towards the characteristics of real-world datasets (Mapillary Vistas, Cityscapes, and KITTI), we already provide both the original rendered frames and the results of EPE [here](https://www.kaggle.com/datasets/stefanospasios/carla2real-enhancing-the-photorealism-of-carla).

### Grand Theft Auto V

To train a model that enhances the photorealism of GTAV towards the characteristics of real-world datasets (Mapillary Vistas and Cityscapes), the results of EPE are already provided by the authors at the [official repository](https://github.com/isl-org/PhotorealismEnhancement). The initial rendered GTAV frames originated from the Playing for Data dataset, which can be downloaded [here](https://download.visinf.tu-darmstadt.de/data/from_games/).

### Starting the Training

After collecting the required datasets, place the training and test sets of the game/simulator dataset into `code/data/train_A` and `code/data/test_A`, respectively. The corresponding photorealism-enhanced images should be transferred into the `code/data/train_B` and `code/data/test_B` directories. To start training, execute the following command:

```javascript
python train.py --dataroot ./data --name REGEN --label_nc 0 --no_instance --gpu_id 0
```

## Testing

To test the framework, we provide pretrained models for `GTAV ‚Üí Cityscapes`, `CARLA ‚Üí Cityscapes`, and `CARLA ‚Üí KITTI`. Download the models from [Google Drive](https://drive.google.com/drive/folders/19Q8E9wy3MR-vUfOfVwytIzv4QNpndYo0?usp=sharing) and transfer them into `code/checkpoints/REGEN/`. Finally, transfer the images that are to be inferred with the model in the `code/data/test_A` directory and execute the following command:

```javascript
python test.py --dataroot ./data --name REGEN --label_nc 0 --no_instance --gpu_id 0
```

The resulting images will be saved in the `code/results/REGEN/images/` directory.

> üìù **Note**: We have already provided some sample screenshots for testing purposes that also include the UI of the game.

<img width="1216" height="337" alt="test_images" src="https://github.com/user-attachments/assets/eb74afeb-604e-4569-81bf-8b97a3c9cb20" />

## Real-Time Inference

We additionally provide two sample scripts for testing the models in real-time conditions. The provided pretrained models should be placed in the same directory as for testing.

### CARLA Simulator

To test the model on CARLA, download the UE4 executable of the simulator from the [official repository](https://github.com/carla-simulator/carla/releases). Particularly, the code was tested with CARLA version 0.9.15. After running the simulator and initializing the world, execute the following command:

```javascript
python carla_test.py --dataroot ./data --name REGEN --label_nc 0 --no_instance --gpu_id 0
```
<img width="1233" height="289" alt="carla" src="https://github.com/user-attachments/assets/72729705-0a54-43ff-b27d-0f0887f6122f" />

### Grand Theft Auto V

To test the model on GTA V, first download and run the game. Considering that the script performs real-time capturing of the game window, set the game in windowed mode with a lower resolution of the monitor (a dual-monitor setup would be ideal). In addition, through the game settings cap the frame rate to 30 FPS to reduce the GPU load. Then execute the following script:

```javascript
python gta_test.py --dataroot ./data --name REGEN --label_nc 0 --no_instance --gpu_id 0
```
> ‚ö†Ô∏è **Warning**: You may need to modify the offsets in line 60 of `gta_test.py` in order to perfectly crop the game window while capturing.

> üìù **Note**: For the best results, it is recommended to download [ScriptHook](https://www.gta5-mods.com/tools/script-hook-v) and [Hood Camera](https://www.gta5-mods.com/scripts/hood-camera) mods, as the PFD dataset used for training is mainly limited to that perspective.

> üìù **Note**: All the available parameters of the model (e.g., for changing the resolution of the resulting images) can be found in `code/options/`.


